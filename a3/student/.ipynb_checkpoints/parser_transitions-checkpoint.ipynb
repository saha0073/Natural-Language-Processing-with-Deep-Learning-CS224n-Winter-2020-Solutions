{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, sentence):\n",
    "        \"\"\"Initializes this partial parse.\n",
    "\n",
    "        @param sentence (list of str): The sentence to be parsed as a list of words.\n",
    "                                        Your code should not modify the sentence.\n",
    "        \"\"\"\n",
    "        # The sentence being parsed is kept for bookkeeping purposes. Do not alter it in your code.\n",
    "        self.sentence = sentence\n",
    "\n",
    "        ### YOUR CODE HERE (3 Lines)\n",
    "        ### Your code should initialize the following fields:\n",
    "        ###     self.stack: The current stack represented as a list with the top of the stack as the\n",
    "        ###                 last element of the list.\n",
    "        ###     self.buffer: The current buffer represented as a list with the first item on the\n",
    "        ###                  buffer as the first item of the list\n",
    "        ###     self.dependencies: The list of dependencies produced so far. Represented as a list of\n",
    "        ###             tuples where each tuple is of the form (head, dependent).\n",
    "        ###             Order for this list doesn't matter.\n",
    "        ###\n",
    "        ### Note: The root token should be represented with the string \"ROOT\"\n",
    "        ###\n",
    "        self.stack=[]\n",
    "        self.stack.append['ROOT']\n",
    "        self.buffer=self.sentence\n",
    "        self.dependencies=[]\n",
    "        \n",
    "\n",
    "        ### END YOUR CODE\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_step(self, transition):\n",
    "        \"\"\"Performs a single parse step by applying the given transition to this partial parse\n",
    "\n",
    "        @param transition (str): A string that equals \"S\", \"LA\", or \"RA\" representing the shift,\n",
    "                                left-arc, and right-arc transitions. You can assume the provided\n",
    "                                transition is a legal transition.\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE (~7-10 Lines)\n",
    "        ### TODO:\n",
    "        ###     Implement a single parsing step, i.e. the logic for the following as\n",
    "        ###     described in the pdf handout:\n",
    "        ###         1. Shift\n",
    "        ###         2. Left Arc\n",
    "        ###         3. Right Arc\n",
    "        if transition==\"S\":\n",
    "            pop_buffer= self.buffer.pop(0)\n",
    "            self.stack.append(pop_buffer)\n",
    "            \n",
    "        if transition==\"LA\":\n",
    "            n=len(self.stack)\n",
    "            last_stack=self.stack[n-1]\n",
    "            sec_pop_stack=self.stack.pop(n-2)\n",
    "            self.dependencies.append((last_stack,sec_pop_stack))\n",
    "            \n",
    "        if transition==\"RA\":\n",
    "            n=len(self.stack)\n",
    "            sec_stack=self.stack[n-2]\n",
    "            last_pop_stack=self.stack.pop(n-1)\n",
    "            self.dependencies.append((sec_stack,last_pop_stack))\n",
    "            \n",
    "\n",
    "        ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch_parse(sentences, model, batch_size):\n",
    "    \"\"\"Parses a list of sentences in minibatches using a model.\n",
    "\n",
    "    @param sentences (list of list of str): A list of sentences to be parsed\n",
    "                                            (each sentence is a list of words and each word is of type string)\n",
    "    @param model (ParserModel): The model that makes parsing decisions. It is assumed to have a function\n",
    "                                model.predict(partial_parses) that takes in a list of PartialParses as input and\n",
    "                                returns a list of transitions predicted for each parse. That is, after calling\n",
    "                                    transitions = model.predict(partial_parses)\n",
    "                                transitions[i] will be the next transition to apply to partial_parses[i].\n",
    "    @param batch_size (int): The number of PartialParses to include in each minibatch\n",
    "\n",
    "\n",
    "    @return dependencies (list of dependency lists): A list where each element is the dependencies\n",
    "                                                    list for a parsed sentence. Ordering should be the\n",
    "                                                    same as in sentences (i.e., dependencies[i] should\n",
    "                                                    contain the parse for sentences[i]).\n",
    "    \"\"\"\n",
    "    dependencies = []\n",
    "\n",
    "    ### YOUR CODE HERE (~8-10 Lines)\n",
    "    ### TODO:\n",
    "    ###     Implement the minibatch parse algorithm as described in the pdf handout\n",
    "    ###\n",
    "    ###     Note: A shallow copy (as denoted in the PDF) can be made with the \"=\" sign in python, e.g.\n",
    "    ###                 unfinished_parses = partial_parses[:].\n",
    "    ###             Here `unfinished_parses` is a shallow copy of `partial_parses`.\n",
    "    ###             In Python, a shallow copied list like `unfinished_parses` does not contain new instances\n",
    "    ###             of the object stored in `partial_parses`. Rather both lists refer to the same objects.\n",
    "    ###             In our case, `partial_parses` contains a list of partial parses. `unfinished_parses`\n",
    "    ###             contains references to the same objects. Thus, you should NOT use the `del` operator\n",
    "    ###             to remove objects from the `unfinished_parses` list. This will free the underlying memory that\n",
    "    ###             is being accessed by `partial_parses` and may cause your code to crash.\n",
    "    \n",
    "    dependencies = [None]*len(sentences)\n",
    "    partial_parses=[None]*len(sentences)\n",
    "    for n in range (len(sentences)):\n",
    "        partial_parses[n]=PartialParse(sentences[n])\n",
    "    unfinished_parses=partial_parses[:]\n",
    "    sentoIdx={}\n",
    "    for n in range(len(sentences)):\n",
    "        sen=\"\".join(sentences[n])\n",
    "        sentoIdx.update({sen:n})\n",
    "    \n",
    "    #suff=np.arange(len(sentences))\n",
    "    #np.random.shuffle(suff)\n",
    "    #fac=len(sentences)//batch_Size\n",
    "    #remin=len(sentences)%batch_size\n",
    "    \n",
    "    #rep=0\n",
    "    while(len(unfinished_parses)>0):\n",
    "        #for rep in range(fac):\n",
    "        if (len(unfinished_parses)<batch_size):\n",
    "            mask=len(unfinished_parses)\n",
    "        else:\n",
    "            mask=batch_size\n",
    "        #if rep==fac: #last batch\n",
    "            #mask=remin\n",
    "        #else:\n",
    "            #mask=batch_size\n",
    "        transitions = model.predict(unfinished_parses[0:mask])\n",
    "        for i in range(mask):\n",
    "            unfinished_parses[i].parse_step(transitions[i])\n",
    "            if all([len(unfinished_parses[i].buffer)==0,len(unfinished_parses[i].stack)==1]):\n",
    "                sen=\"\".join(unfinished_parses[i].sentence)\n",
    "                idx=sentoIdx[sen]\n",
    "                dependencies[idx]=unfinished_parses[i].dependencies\n",
    "            #all ([ncor >=0, ncor<len(corpus[corp])]):\n",
    "        #for i in len(unfinishedrange(mask):\n",
    "        #i=0\n",
    "        #maxsen=len(unfinished_parses)\n",
    "        #while i<maxsen:\n",
    "        for parse in unfinished_parses:\n",
    "            if all([len(parse.buffer)==0,len(parse.stack)==1]):\n",
    "                unfinished_parses.remove(parse)\n",
    "  \n",
    "        \n",
    "    #print(dependencies)\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['parse', 'sentence']\n"
     ]
    }
   ],
   "source": [
    "#verts = [None] * 10\n",
    "#5.//2.\n",
    "sentence = [\"parse\", \"this\", \"sentence\"]\n",
    "sen=\"\".join(sentence)\n",
    "#print('type',type(sen))\n",
    "#print('hash',hash(sen))\n",
    "#sentence[3]\n",
    "for wrd in sentence:\n",
    "    if wrd==\"this\":\n",
    "        sentence.remove(wrd)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(verts)\n",
    "verts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibatch_parse test passed!\n"
     ]
    }
   ],
   "source": [
    "test_minibatch_parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def test_step(name, transition, stack, buf, deps,\n",
    "              ex_stack, ex_buf, ex_deps):\n",
    "    \"\"\"Tests that a single parse step returns the expected output\"\"\"\n",
    "    pp = PartialParse([])\n",
    "    pp.stack, pp.buffer, pp.dependencies = stack, buf, deps\n",
    "\n",
    "    pp.parse_step(transition)\n",
    "    stack, buf, deps = (tuple(pp.stack), tuple(pp.buffer), tuple(sorted(pp.dependencies)))\n",
    "    assert stack == ex_stack, \\\n",
    "        \"{:} test resulted in stack {:}, expected {:}\".format(name, stack, ex_stack)\n",
    "    assert buf == ex_buf, \\\n",
    "        \"{:} test resulted in buffer {:}, expected {:}\".format(name, buf, ex_buf)\n",
    "    assert deps == ex_deps, \\\n",
    "        \"{:} test resulted in dependency list {:}, expected {:}\".format(name, deps, ex_deps)\n",
    "    print(\"{:} test passed!\".format(name))\n",
    "\n",
    "\n",
    "def test_parse_step():\n",
    "    \"\"\"Simple tests for the PartialParse.parse_step function\n",
    "    Warning: these are not exhaustive\n",
    "    \"\"\"\n",
    "    test_step(\"SHIFT\", \"S\", [\"ROOT\", \"the\"], [\"cat\", \"sat\"], [],\n",
    "              (\"ROOT\", \"the\", \"cat\"), (\"sat\",), ())\n",
    "    test_step(\"LEFT-ARC\", \"LA\", [\"ROOT\", \"the\", \"cat\"], [\"sat\"], [],\n",
    "              (\"ROOT\", \"cat\",), (\"sat\",), ((\"cat\", \"the\"),))\n",
    "    test_step(\"RIGHT-ARC\", \"RA\", [\"ROOT\", \"run\", \"fast\"], [], [],\n",
    "              (\"ROOT\", \"run\",), (), ((\"run\", \"fast\"),))\n",
    "\n",
    "\n",
    "def test_parse():\n",
    "    \"\"\"Simple tests for the PartialParse.parse function\n",
    "    Warning: these are not exhaustive\n",
    "    \"\"\"\n",
    "    sentence = [\"parse\", \"this\", \"sentence\"]\n",
    "    dependencies = PartialParse(sentence).parse([\"S\", \"S\", \"S\", \"LA\", \"RA\", \"RA\"])\n",
    "    dependencies = tuple(sorted(dependencies))\n",
    "    expected = (('ROOT', 'parse'), ('parse', 'sentence'), ('sentence', 'this'))\n",
    "    assert dependencies == expected,  \\\n",
    "        \"parse test resulted in dependencies {:}, expected {:}\".format(dependencies, expected)\n",
    "    assert tuple(sentence) == (\"parse\", \"this\", \"sentence\"), \\\n",
    "        \"parse test failed: the input sentence should not be modified\"\n",
    "    print(\"parse test passed!\")\n",
    "    \n",
    "def test_minibatch_parse():\n",
    "    \"\"\"Simple tests for the minibatch_parse function\n",
    "    Warning: these are not exhaustive\n",
    "    \"\"\"\n",
    "\n",
    "    # Unidirectional arcs test\n",
    "    sentences = [[\"right\", \"arcs\", \"only\"],\n",
    "                 [\"right\", \"arcs\", \"only\", \"again\"],\n",
    "                 [\"left\", \"arcs\", \"only\"],\n",
    "                 [\"left\", \"arcs\", \"only\", \"again\"]]\n",
    "    deps = minibatch_parse(sentences, DummyModel(), 2)\n",
    "    test_dependencies(\"minibatch_parse\", deps[0],\n",
    "                      (('ROOT', 'right'), ('arcs', 'only'), ('right', 'arcs')))\n",
    "    test_dependencies(\"minibatch_parse\", deps[1],\n",
    "                      (('ROOT', 'right'), ('arcs', 'only'), ('only', 'again'), ('right', 'arcs')))\n",
    "    test_dependencies(\"minibatch_parse\", deps[2],\n",
    "                      (('only', 'ROOT'), ('only', 'arcs'), ('only', 'left')))\n",
    "    test_dependencies(\"minibatch_parse\", deps[3],\n",
    "                      (('again', 'ROOT'), ('again', 'arcs'), ('again', 'left'), ('again', 'only')))\n",
    "\n",
    "    # Out-of-bound test\n",
    "    sentences = [[\"right\"]]\n",
    "    deps = minibatch_parse(sentences, DummyModel(), 2)\n",
    "    test_dependencies(\"minibatch_parse\", deps[0], (('ROOT', 'right'),))\n",
    "\n",
    "    # Mixed arcs test\n",
    "    sentences = [[\"this\", \"is\", \"interleaving\", \"dependency\", \"test\"]]\n",
    "    deps = minibatch_parse(sentences, DummyModel(mode=\"interleave\"), 1)\n",
    "    test_dependencies(\"minibatch_parse\", deps[0],\n",
    "                      (('ROOT', 'is'), ('dependency', 'interleaving'),\n",
    "                      ('dependency', 'test'), ('is', 'dependency'), ('is', 'this')))\n",
    "    print(\"minibatch_parse test passed!\")\n",
    "\n",
    "def test_dependencies(name, deps, ex_deps):\n",
    "    \"\"\"Tests the provided dependencies match the expected dependencies\"\"\"\n",
    "    deps = tuple(sorted(deps))\n",
    "    assert deps == ex_deps, \\\n",
    "        \"{:} test resulted in dependency list {:}, expected {:}\".format(name, deps, ex_deps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHIFT test passed!\n",
      "LEFT-ARC test passed!\n",
      "RIGHT-ARC test passed!\n",
      "parse test passed!\n"
     ]
    }
   ],
   "source": [
    "test_parse_step()\n",
    "test_parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartialParse(object):\n",
    "    def __init__(self, sentence):\n",
    "        \"\"\"Initializes this partial parse.\n",
    "\n",
    "        @param sentence (list of str): The sentence to be parsed as a list of words.\n",
    "                                        Your code should not modify the sentence.\n",
    "        \"\"\"\n",
    "        # The sentence being parsed is kept for bookkeeping purposes. Do not alter it in your code.\n",
    "        self.sentence = sentence\n",
    "\n",
    "        ### YOUR CODE HERE (3 Lines)\n",
    "        ### Your code should initialize the following fields:\n",
    "        ###     self.stack: The current stack represented as a list with the top of the stack as the\n",
    "        ###                 last element of the list.\n",
    "        ###     self.buffer: The current buffer represented as a list with the first item on the\n",
    "        ###                  buffer as the first item of the list\n",
    "        ###     self.dependencies: The list of dependencies produced so far. Represented as a list of\n",
    "        ###             tuples where each tuple is of the form (head, dependent).\n",
    "        ###             Order for this list doesn't matter.\n",
    "        ###\n",
    "        ### Note: The root token should be represented with the string \"ROOT\"\n",
    "        ###\n",
    "        self.stack=[]\n",
    "        self.stack.append('ROOT')\n",
    "        self.buffer=self.sentence.copy()\n",
    "        self.dependencies=[]\n",
    "\n",
    "        ### END YOUR CODE\n",
    "\n",
    "\n",
    "    def parse_step(self, transition):\n",
    "        \"\"\"Performs a single parse step by applying the given transition to this partial parse\n",
    "\n",
    "        @param transition (str): A string that equals \"S\", \"LA\", or \"RA\" representing the shift,\n",
    "                                left-arc, and right-arc transitions. You can assume the provided\n",
    "                                transition is a legal transition.\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE (~7-10 Lines)\n",
    "        ### TODO:\n",
    "        ###     Implement a single parsing step, i.e. the logic for the following as\n",
    "        ###     described in the pdf handout:\n",
    "        ###         1. Shift\n",
    "        ###         2. Left Arc\n",
    "        ###         3. Right Arc\n",
    "        if transition==\"S\":\n",
    "            pop_buffer= self.buffer.pop(0)\n",
    "            self.stack.append(pop_buffer)\n",
    "            \n",
    "        if transition==\"LA\":\n",
    "            n=len(self.stack)\n",
    "            last_stack=self.stack[n-1]\n",
    "            sec_pop_stack=self.stack.pop(n-2)\n",
    "            self.dependencies.append((last_stack,sec_pop_stack))\n",
    "            \n",
    "        if transition==\"RA\":\n",
    "            n=len(self.stack)\n",
    "            sec_stack=self.stack[n-2]\n",
    "            last_pop_stack=self.stack.pop(n-1)\n",
    "            self.dependencies.append((sec_stack,last_pop_stack))\n",
    "        \n",
    "\n",
    "        ### END YOUR CODE\n",
    "\n",
    "    def parse(self, transitions):\n",
    "        \"\"\"Applies the provided transitions to this PartialParse\n",
    "\n",
    "        @param transitions (list of str): The list of transitions in the order they should be applied\n",
    "\n",
    "        @return dsependencies (list of string tuples): The list of dependencies produced when\n",
    "                                                        parsing the sentence. Represented as a list of\n",
    "                                                        tuples where each tuple is of the form (head, dependent).\n",
    "        \"\"\"\n",
    "        for transition in transitions:\n",
    "            self.parse_step(transition)\n",
    "        return self.dependencies\n",
    "    \n",
    "class DummyModel(object):\n",
    "    \"\"\"Dummy model for testing the minibatch_parse function\n",
    "    \"\"\"\n",
    "    def __init__(self, mode = \"unidirectional\"):\n",
    "        self.mode = mode\n",
    "\n",
    "    def predict(self, partial_parses):\n",
    "        if self.mode == \"unidirectional\":\n",
    "            return self.unidirectional_predict(partial_parses)\n",
    "        elif self.mode == \"interleave\":\n",
    "            return self.interleave_predict(partial_parses)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def unidirectional_predict(self, partial_parses):\n",
    "        \"\"\"First shifts everything onto the stack and then does exclusively right arcs if the first word of\n",
    "        the sentence is \"right\", \"left\" if otherwise.\n",
    "        \"\"\"\n",
    "        return [(\"RA\" if pp.stack[1] is \"right\" else \"LA\") if len(pp.buffer) == 0 else \"S\"\n",
    "                for pp in partial_parses]\n",
    "\n",
    "    def interleave_predict(self, partial_parses):\n",
    "        \"\"\"First shifts everything onto the stack and then interleaves \"right\" and \"left\".\n",
    "        \"\"\"\n",
    "        return [(\"RA\" if len(pp.stack) % 2 == 0 else \"LA\") if len(pp.buffer) == 0 else \"S\"\n",
    "                for pp in partial_parses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_parses = [PartialParse(sentence) for sentence in sentences]\n",
    "    unfinished_parses = partial_parses[:]\n",
    "    \n",
    "    while len(unfinished_parses) > 0:\n",
    "        batch = unfinished_parses[:batch_size]\n",
    "        transitions = model.predict(batch)\n",
    "        _ = [partial_parse.parse_step(transition) for partial_parse, transition in zip(batch, transitions)]\n",
    "        unfinished_parses = [partial_parse for partial_parse in partial_parses if not (len(partial_parse.stack) == 1 and \n",
    "                                                                                      len(partial_parse.buffer) == 0)]\n",
    "    dependencies += [partial_parse.dependencies for partial_parse in partial_parses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    dependencies = [None]*len(sentences)\n",
    "    partial_parses=[None]*len(sentences)\n",
    "    print('sentences',len(sentences))\n",
    "    print('batch_size',batch_size)\n",
    "    for n in range (len(sentences)):\n",
    "        partial_parses[n]=PartialParse(sentences[n])\n",
    "    unfinished_parses=partial_parses[:]\n",
    "    sentoIdx={}\n",
    "    for n in range(len(sentences)):\n",
    "        #print(sentences[n])\n",
    "        sen=\"\".join(sentences[n])\n",
    "        sentoIdx.update({sen:n})\n",
    "    \n",
    "    #suff=np.arange(len(sentences))\n",
    "    #np.random.shuffle(suff)\n",
    "    #fac=len(sentences)//batch_Size\n",
    "    #remin=len(sentences)%batch_size\n",
    "    \n",
    "    #rep=0\n",
    "    while(len(unfinished_parses)>0):\n",
    "        #for rep in range(fac):\n",
    "        if (len(unfinished_parses)<batch_size):\n",
    "            mask=len(unfinished_parses)\n",
    "        else:\n",
    "            mask=batch_size\n",
    "        #if rep==fac: #last batch\n",
    "            #mask=remin\n",
    "        #else:\n",
    "            #mask=batch_size\n",
    "        transitions = model.predict(unfinished_parses[0:mask])\n",
    "        for i in range(mask):\n",
    "            unfinished_parses[i].parse_step(transitions[i])\n",
    "            if all([len(unfinished_parses[i].buffer)==0,len(unfinished_parses[i].stack)==1]):\n",
    "                sen=\"\".join(unfinished_parses[i].sentence)\n",
    "                idx=sentoIdx[sen]\n",
    "                dependencies[idx]=unfinished_parses[i].dependencies\n",
    "            #all ([ncor >=0, ncor<len(corpus[corp])]):\n",
    "        #for i in len(unfinishedrange(mask):\n",
    "        #i=0\n",
    "        #maxsen=len(unfinished_parses)\n",
    "        #while i<maxsen:\n",
    "        for parse in unfinished_parses:\n",
    "            if all([len(parse.buffer)==0,len(parse.stack)==1]):\n",
    "                unfinished_parses.remove(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n",
   "language": "python",
   "name": "cs224n"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
